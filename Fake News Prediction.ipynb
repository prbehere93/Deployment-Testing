{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "To predict from the Title and the Text of an Article if the news is Real or Fake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('fake_or_real_news.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6335, 4)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['label']\n",
    "x=data['text']+data['title']  #Merging both of the columns to obtain a single col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6335"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.33,random_state=44) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to preprocess(tokenize) text we will use a CountVectorizer and also find the Tfidf for the text data.\n",
    "We will utilize the method which gives us the best result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#Bag-of-words\n",
    "cv=CountVectorizer(stop_words=\"english\")\n",
    "tf = TfidfVectorizer(stop_words='english',max_df=0.7) #Removes Stopwords\n",
    "#Turns words into their base form\n",
    "wl=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating pickles for the transformers\n",
    "wl=WordNetLemmatizer()\n",
    "pickle.dump(wl,open(\"wl.pkl\",\"wb\"))\n",
    "tf = TfidfVectorizer(stop_words='english',max_df=0.7) #Removes Stopwords\n",
    "tf.fit(x_train)\n",
    "pickle.dump(tf,open(\"tfidf.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['REAL']\n"
     ]
    }
   ],
   "source": [
    "c=x[4]\n",
    "c=pd.Series(c)\n",
    "c=c.apply(wl.lemmatize)\n",
    "c=tf.transform(c)\n",
    "print(nb.predict(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.apply(wl.lemmatize)\n",
    "x_test=x_test.apply(wl.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_count=cv.fit_transform(x_train)\n",
    "x_test_count=cv.transform(x_test)\n",
    "x_train_tfidf=tf.fit_transform(x_train)\n",
    "x_test_tfidf=tf.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '0000', '000000031', '000035', '000billion', '000ft', '000x', '001', '0011']\n"
     ]
    }
   ],
   "source": [
    "print(cv.get_feature_names()[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Naive Bayes for text classification\n",
    "Naive Bayes model works well with text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.8943089430894309\n",
      "\n",
      "Alpha:  0.1\n",
      "Score:  0.9105691056910569\n",
      "\n",
      "Alpha:  0.2\n",
      "Score:  0.9019607843137255\n",
      "\n",
      "Alpha:  0.30000000000000004\n",
      "Score:  0.8957436633189861\n",
      "\n",
      "Alpha:  0.4\n",
      "Score:  0.890961262553802\n",
      "\n",
      "Alpha:  0.5\n",
      "Score:  0.8880918220946915\n",
      "\n",
      "Alpha:  0.6000000000000001\n",
      "Score:  0.882831181252989\n",
      "\n",
      "Alpha:  0.7000000000000001\n",
      "Score:  0.877092300334768\n",
      "\n",
      "Alpha:  0.8\n",
      "Score:  0.8713534194165471\n",
      "\n",
      "Alpha:  0.9\n",
      "Score:  0.8689622190339551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "# Create the list of alphas: alphas\n",
    "import numpy as np\n",
    "alphas = np.arange(0,1,0.1) #From 0 to 1 with 0.1 intervals\n",
    "\n",
    "# Define train_and_predict()\n",
    "def train_and_predict(alpha):\n",
    "    # Instantiate the classifier: nb_classifier\n",
    "    nb_classifier = MultinomialNB(alpha=alpha)\n",
    "    # Fit to the training data\n",
    "    nb_classifier.fit(x_train_tfidf,y_train)\n",
    "    # Predict the labels: pred\n",
    "    pred = nb_classifier.predict(x_test_tfidf)\n",
    "    # Compute accuracy: score\n",
    "    score = metrics.accuracy_score(y_test,pred)\n",
    "    return score\n",
    "\n",
    "# Iterate over the alphas and print the corresponding score\n",
    "for alpha in alphas:\n",
    "    print('Alpha: ', alpha)\n",
    "    print('Score: ', train_and_predict(alpha))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the optimum value of alpha is 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb=MultinomialNB(alpha=0.1) #Multinomial Naive Bayes model\n",
    "nb2=MultinomialNB(alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2091x56885 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 553473 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9086561453849833"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(x_train_count,y_train)\n",
    "pred=nb.predict(x_test_count)\n",
    "metrics.accuracy_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9086561453849833"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb2.fit(x_train_tfidf,y_train)\n",
    "pred2=nb2.predict(x_test_tfidf)\n",
    "metrics.accuracy_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, both the techniques give us a similar result.\n",
    "\n",
    "Also, our predictor works reasonably well i.e. with an accuracy of above 90% on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[910, 107],\n",
       "       [ 84, 990]], dtype=int64)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the class labels: class_labels\n",
    "class_labels = nb.classes_\n",
    "\n",
    "# Extract the features: feature_names\n",
    "feature_names = tf.get_feature_names()\n",
    "\n",
    "# Zip the feature names together with the coefficient array and sort by weights: feat_with_weights\n",
    "feat_with_weights = sorted(zip(nb.coef_[0], feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('FAKE',\n",
       " [(-16.08754726423953, '000035'),\n",
       "  (-16.08754726423953, '000billion'),\n",
       "  (-16.08754726423953, '0011'),\n",
       "  (-16.08754726423953, '004s'),\n",
       "  (-16.08754726423953, '005'),\n",
       "  (-16.08754726423953, '005s'),\n",
       "  (-16.08754726423953, '00684'),\n",
       "  (-16.08754726423953, '006s'),\n",
       "  (-16.08754726423953, '007'),\n",
       "  (-16.08754726423953, '007s'),\n",
       "  (-16.08754726423953, '008s'),\n",
       "  (-16.08754726423953, '00am'),\n",
       "  (-16.08754726423953, '00pm'),\n",
       "  (-16.08754726423953, '013c2812c9'),\n",
       "  (-16.08754726423953, '015'),\n",
       "  (-16.08754726423953, '016'),\n",
       "  (-16.08754726423953, '01am'),\n",
       "  (-16.08754726423953, '020'),\n",
       "  (-16.08754726423953, '022'),\n",
       "  (-16.08754726423953, '02714'),\n",
       "  (-16.08754726423953, '02870'),\n",
       "  (-16.08754726423953, '030'),\n",
       "  (-16.08754726423953, '031'),\n",
       "  (-16.08754726423953, '032'),\n",
       "  (-16.08754726423953, '0325'),\n",
       "  (-16.08754726423953, '033'),\n",
       "  (-16.08754726423953, '03747'),\n",
       "  (-16.08754726423953, '039'),\n",
       "  (-16.08754726423953, '03eb'),\n",
       "  (-16.08754726423953, '04pm')])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first class label and the top 30 feat_with_weights entries (indicative of FAKE news)\n",
    "class_labels[0], feat_with_weights[:30]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('REAL',\n",
       " [(-6.2395195689077685, 'going'),\n",
       "  (-6.233722756722502, 'news'),\n",
       "  (-6.225871779517841, 'white'),\n",
       "  (-6.221190610041609, 'gop'),\n",
       "  (-6.212407747218889, 'bush'),\n",
       "  (-6.16518889095315, 'democratic'),\n",
       "  (-6.1486443064824465, 'cruz'),\n",
       "  (-6.125743634880566, 'year'),\n",
       "  (-6.125272070220313, 'presidential'),\n",
       "  (-6.118693408272149, 'voters'),\n",
       "  (-6.113088797832822, 'republicans'),\n",
       "  (-6.08100685664732, 'political'),\n",
       "  (-6.008385197631241, 'percent'),\n",
       "  (-5.968504882037868, 'house'),\n",
       "  (-5.966893992075728, 'sanders'),\n",
       "  (-5.949343384036576, 'like'),\n",
       "  (-5.942644115601743, 'states'),\n",
       "  (-5.934819655667917, 'just'),\n",
       "  (-5.904876149506519, 'time'),\n",
       "  (-5.765645473309027, 'party'),\n",
       "  (-5.664343724591964, 'republican'),\n",
       "  (-5.571824366398973, 'campaign'),\n",
       "  (-5.51492350110496, 'new'),\n",
       "  (-5.467904263094537, 'president'),\n",
       "  (-5.467415755232057, 'people'),\n",
       "  (-5.448068582151567, 'obama'),\n",
       "  (-5.426272452663007, 'state'),\n",
       "  (-4.89771000298504, 'clinton'),\n",
       "  (-4.525822111335696, 'trump'),\n",
       "  (-4.451157156774407, 'said')])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the second class label and the bottom 30 feat_with_weights entries (indicative of REAL news)\n",
    "class_labels[1], feat_with_weights[-30:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, this model makes some sense. Most of the words indicating REAL news are related to politics while the ones indicating FAKE news are pretty much gibberish.\n",
    "\n",
    "There is still some room for improvement in this model. We can eliminate a few small words (let's say less than 2 letters) maybe even single digit numbers and see how the model behaves.\n",
    "\n",
    "We can also try some other ML algorithms to see how the accuracy changes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model using pickle\n",
    "pickle.dump(nb2,open('model.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
